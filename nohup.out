srun: job 61872 queued and waiting for resources
srun: job 61872 has been allocated resources
srun: Job 61872 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device
srun: error: Not using a pseudo-terminal, disregarding --pty option
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
RANK and WORLD_SIZE in environment: 1/4
RANK and WORLD_SIZE in environment: 3/4
RANK and WORLD_SIZE in environment: 0/4
RANK and WORLD_SIZE in environment: 2/4
srun: got SIGCONT
Image size: 480
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=7.29s)
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=7.02s)
local rank 0 / global rank 0 successfully built train dataset.
lavt
Window size 12!
Initializing Multi-modal Swin Transformer weights from ./pretrained_weights/swin_base_patch4_window12_384_22k.pth
Epoch: [0]  [  0/378]  eta: 0:45:33  lr: 4.999702379968167e-05  loss: 0.6706 (0.6706)  time: 7.2326  data: 1.2948  max mem: 71773
srun: forcing job termination
srun: Job step aborted: Waiting up to 2 seconds for job step to finish.
srun: Easily find out why your job was killed by following the link below:
	https://docs.phoenix.sensetime.com/FAQ/SlurmFAQ/Find-out-why-my-job-was-killed/
slurmstepd: error: *** STEP 61872.0 ON SH-IDC1-10-140-24-89 CANCELLED AT 2022-10-04T00:53:51 ***
srun: error: Timed out waiting for job step to complete
srun: job 62555 queued and waiting for resources
srun: job 62555 has been allocated resources
srun: Job 62555 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device
srun: error: Not using a pseudo-terminal, disregarding --pty option
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
RANK and WORLD_SIZE in environment: 1/2
RANK and WORLD_SIZE in environment: 0/2
Image size: 480
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.89s)
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.90s)
local rank 0 / global rank 0 successfully built train dataset.
lavt
Window size 12!
Initializing Multi-modal Swin Transformer weights from ./pretrained_weights/swin_base_patch4_window12_384_22k.pth
Epoch: [0]  [  0/757]  eta: 1:31:12  lr: 4.9998513868087606e-05  loss: 0.7443 (0.7443)  time: 7.2286  data: 1.3129  max mem: 71773
Epoch: [0]  [ 10/757]  eta: 1:08:49  lr: 4.9983652278986757e-05  loss: 0.6904 (0.6889)  time: 5.5281  data: 0.1389  max mem: 74195
Epoch: [0]  [ 20/757]  eta: 1:05:36  lr: 4.996879019889397e-05  loss: 0.6254 (0.6316)  time: 5.2474  data: 0.0197  max mem: 74195
Epoch: [0]  [ 30/757]  eta: 1:03:57  lr: 4.9953927627630757e-05  loss: 0.4514 (0.5500)  time: 5.1413  data: 0.0191  max mem: 74195
Epoch: [0]  [ 40/757]  eta: 1:03:32  lr: 4.9939064565018504e-05  loss: 0.3528 (0.5018)  time: 5.2916  data: 0.0206  max mem: 74195
Epoch: [0]  [ 50/757]  eta: 1:01:42  lr: 4.9924201010878466e-05  loss: 0.3351 (0.4662)  time: 5.1734  data: 0.0201  max mem: 74195
Epoch: [0]  [ 60/757]  eta: 1:00:39  lr: 4.990933696503178e-05  loss: 0.3229 (0.4460)  time: 5.0266  data: 0.0196  max mem: 74195
Epoch: [0]  [ 70/757]  eta: 0:59:38  lr: 4.989447242729946e-05  loss: 0.3245 (0.4306)  time: 5.1370  data: 0.0199  max mem: 74195
Epoch: [0]  [ 80/757]  eta: 0:58:31  lr: 4.987960739750238e-05  loss: 0.3175 (0.4177)  time: 5.0807  data: 0.0203  max mem: 74195
Epoch: [0]  [ 90/757]  eta: 0:57:40  lr: 4.986474187546132e-05  loss: 0.3099 (0.4070)  time: 5.1121  data: 0.0205  max mem: 74195
Epoch: [0]  [100/757]  eta: 0:56:42  lr: 4.9849875860996906e-05  loss: 0.3187 (0.3999)  time: 5.1450  data: 0.0200  max mem: 74195
Epoch: [0]  [110/757]  eta: 0:55:49  lr: 4.983500935392965e-05  loss: 0.3350 (0.3921)  time: 5.1278  data: 0.0199  max mem: 74195
Epoch: [0]  [120/757]  eta: 0:55:01  lr: 4.982014235407995e-05  loss: 0.3080 (0.3860)  time: 5.2039  data: 0.0196  max mem: 74195
Epoch: [0]  [130/757]  eta: 0:53:54  lr: 4.980527486126806e-05  loss: 0.3080 (0.3804)  time: 5.0598  data: 0.0190  max mem: 74195
Epoch: [0]  [140/757]  eta: 0:53:09  lr: 4.979040687531412e-05  loss: 0.3027 (0.3748)  time: 5.0863  data: 0.0189  max mem: 74195
Epoch: [0]  [150/757]  eta: 0:52:07  lr: 4.9775538396038144e-05  loss: 0.2859 (0.3691)  time: 5.1137  data: 0.0185  max mem: 74195
Epoch: [0]  [160/757]  eta: 0:51:08  lr: 4.9760669423260014e-05  loss: 0.2859 (0.3644)  time: 4.9295  data: 0.0178  max mem: 74195
Epoch: [0]  [170/757]  eta: 0:50:21  lr: 4.974579995679949e-05  loss: 0.2955 (0.3606)  time: 5.1019  data: 0.0175  max mem: 74195
Epoch: [0]  [180/757]  eta: 0:49:31  lr: 4.9730929996476225e-05  loss: 0.2834 (0.3562)  time: 5.2420  data: 0.0176  max mem: 74195
Epoch: [0]  [190/757]  eta: 0:48:37  lr: 4.9716059542109697e-05  loss: 0.2760 (0.3525)  time: 5.1282  data: 0.0186  max mem: 74195
Epoch: [0]  [200/757]  eta: 0:47:51  lr: 4.970118859351932e-05  loss: 0.2751 (0.3487)  time: 5.1875  data: 0.0191  max mem: 74195
Epoch: [0]  [210/757]  eta: 0:46:51  lr: 4.968631715052433e-05  loss: 0.2727 (0.3452)  time: 5.0918  data: 0.0196  max mem: 74195
Epoch: [0]  [220/757]  eta: 0:46:00  lr: 4.9671445212943876e-05  loss: 0.2750 (0.3427)  time: 5.0039  data: 0.0195  max mem: 74195
Epoch: [0]  [230/757]  eta: 0:45:07  lr: 4.965657278059695e-05  loss: 0.2658 (0.3389)  time: 5.1047  data: 0.0195  max mem: 74195
Epoch: [0]  [240/757]  eta: 0:44:13  lr: 4.964169985330244e-05  loss: 0.2524 (0.3356)  time: 5.0438  data: 0.0198  max mem: 74195
Epoch: [0]  [250/757]  eta: 0:43:21  lr: 4.962682643087909e-05  loss: 0.2537 (0.3324)  time: 5.0761  data: 0.0185  max mem: 74195
Epoch: [0]  [260/757]  eta: 0:42:34  lr: 4.961195251314552e-05  loss: 0.2512 (0.3292)  time: 5.2219  data: 0.0187  max mem: 74195
Epoch: [0]  [270/757]  eta: 0:41:44  lr: 4.9597078099920255e-05  loss: 0.2551 (0.3266)  time: 5.2830  data: 0.0191  max mem: 74195
Epoch: [0]  [280/757]  eta: 0:40:52  lr: 4.958220319102163e-05  loss: 0.2557 (0.3239)  time: 5.1604  data: 0.0186  max mem: 74195
Epoch: [0]  [290/757]  eta: 0:40:04  lr: 4.956732778626791e-05  loss: 0.2344 (0.3206)  time: 5.2146  data: 0.0186  max mem: 74195
Epoch: [0]  [300/757]  eta: 0:39:08  lr: 4.9552451885477214e-05  loss: 0.2302 (0.3177)  time: 5.1119  data: 0.0178  max mem: 74195
Epoch: [0]  [310/757]  eta: 0:38:17  lr: 4.953757548846751e-05  loss: 0.2329 (0.3154)  time: 5.0298  data: 0.0171  max mem: 74195
Epoch: [0]  [320/757]  eta: 0:37:26  lr: 4.952269859505669e-05  loss: 0.2341 (0.3131)  time: 5.1639  data: 0.0176  max mem: 74195
Epoch: [0]  [330/757]  eta: 0:36:33  lr: 4.950782120506247e-05  loss: 0.2330 (0.3107)  time: 5.0825  data: 0.0186  max mem: 74195
Epoch: [0]  [340/757]  eta: 0:35:42  lr: 4.949294331830245e-05  loss: 0.2268 (0.3085)  time: 5.0734  data: 0.0182  max mem: 74195
Epoch: [0]  [350/757]  eta: 0:34:49  lr: 4.947806493459413e-05  loss: 0.2340 (0.3067)  time: 5.0604  data: 0.0176  max mem: 74195
Epoch: [0]  [360/757]  eta: 0:33:58  lr: 4.9463186053754845e-05  loss: 0.2493 (0.3051)  time: 5.1019  data: 0.0180  max mem: 74195
Epoch: [0]  [370/757]  eta: 0:33:06  lr: 4.9448306675601816e-05  loss: 0.2384 (0.3032)  time: 5.1276  data: 0.0182  max mem: 74195
Epoch: [0]  [380/757]  eta: 0:32:14  lr: 4.943342679995214e-05  loss: 0.2445 (0.3016)  time: 5.0539  data: 0.0182  max mem: 74195
Epoch: [0]  [390/757]  eta: 0:31:22  lr: 4.941854642662279e-05  loss: 0.2306 (0.2996)  time: 5.0564  data: 0.0187  max mem: 74195
Epoch: [0]  [400/757]  eta: 0:30:30  lr: 4.9403665555430586e-05  loss: 0.2228 (0.2978)  time: 5.0873  data: 0.0185  max mem: 74195
Epoch: [0]  [410/757]  eta: 0:29:39  lr: 4.9388784186192255e-05  loss: 0.2272 (0.2959)  time: 5.1149  data: 0.0189  max mem: 74195
Epoch: [0]  [420/757]  eta: 0:28:47  lr: 4.937390231872436e-05  loss: 0.2135 (0.2941)  time: 5.0650  data: 0.0196  max mem: 74195
Epoch: [0]  [430/757]  eta: 0:27:55  lr: 4.935901995284336e-05  loss: 0.2230 (0.2924)  time: 5.0661  data: 0.0187  max mem: 74195
Epoch: [0]  [440/757]  eta: 0:27:04  lr: 4.9344137088365576e-05  loss: 0.2230 (0.2911)  time: 5.0937  data: 0.0184  max mem: 74195
Epoch: [0]  [450/757]  eta: 0:26:12  lr: 4.9329253725107196e-05  loss: 0.2319 (0.2899)  time: 5.0465  data: 0.0180  max mem: 74195
Epoch: [0]  [460/757]  eta: 0:25:22  lr: 4.9314369862884286e-05  loss: 0.2288 (0.2885)  time: 5.1818  data: 0.0190  max mem: 74195
Epoch: [0]  [470/757]  eta: 0:24:36  lr: 4.929948550151277e-05  loss: 0.2076 (0.2868)  time: 5.6671  data: 0.0187  max mem: 74195
Epoch: [0]  [480/757]  eta: 0:23:46  lr: 4.9284600640808464e-05  loss: 0.2059 (0.2855)  time: 5.6636  data: 0.0181  max mem: 74195
Epoch: [0]  [490/757]  eta: 0:22:55  lr: 4.926971528058704e-05  loss: 0.2096 (0.2839)  time: 5.2892  data: 0.0188  max mem: 74195
Epoch: [0]  [500/757]  eta: 0:22:03  lr: 4.925482942066402e-05  loss: 0.2207 (0.2830)  time: 5.1288  data: 0.0168  max mem: 74195
Epoch: [0]  [510/757]  eta: 0:21:11  lr: 4.9239943060854845e-05  loss: 0.2281 (0.2822)  time: 5.1087  data: 0.0155  max mem: 74195
Epoch: [0]  [520/757]  eta: 0:20:21  lr: 4.9225056200974786e-05  loss: 0.2260 (0.2812)  time: 5.2549  data: 0.0173  max mem: 74195
Epoch: [0]  [530/757]  eta: 0:19:30  lr: 4.9210168840838986e-05  loss: 0.2103 (0.2795)  time: 5.3253  data: 0.0197  max mem: 74195
Epoch: [0]  [540/757]  eta: 0:18:38  lr: 4.919528098026249e-05  loss: 0.1924 (0.2779)  time: 5.2686  data: 0.0195  max mem: 74195
Epoch: [0]  [550/757]  eta: 0:17:47  lr: 4.9180392619060175e-05  loss: 0.1924 (0.2764)  time: 5.1531  data: 0.0180  max mem: 74195
Epoch: [0]  [560/757]  eta: 0:16:55  lr: 4.916550375704679e-05  loss: 0.1933 (0.2751)  time: 5.1085  data: 0.0175  max mem: 74195
Epoch: [0]  [570/757]  eta: 0:16:04  lr: 4.9150614394036984e-05  loss: 0.1998 (0.2739)  time: 5.2291  data: 0.0253  max mem: 74195
Epoch: [0]  [580/757]  eta: 0:15:13  lr: 4.913572452984526e-05  loss: 0.1987 (0.2727)  time: 5.3111  data: 0.0285  max mem: 74195
Epoch: [0]  [590/757]  eta: 0:14:22  lr: 4.912083416428597e-05  loss: 0.1980 (0.2716)  time: 5.4214  data: 0.0261  max mem: 74195
Epoch: [0]  [600/757]  eta: 0:13:30  lr: 4.910594329717335e-05  loss: 0.1945 (0.2707)  time: 5.3084  data: 0.0254  max mem: 74195
Epoch: [0]  [610/757]  eta: 0:12:38  lr: 4.909105192832152e-05  loss: 0.2017 (0.2698)  time: 5.0024  data: 0.0206  max mem: 74195
Epoch: [0]  [620/757]  eta: 0:11:47  lr: 4.9076160057544444e-05  loss: 0.2066 (0.2686)  time: 5.1034  data: 0.0185  max mem: 74195
Epoch: [0]  [630/757]  eta: 0:10:55  lr: 4.9061267684655966e-05  loss: 0.2131 (0.2677)  time: 5.1042  data: 0.0185  max mem: 74195
Epoch: [0]  [640/757]  eta: 0:10:03  lr: 4.904637480946979e-05  loss: 0.2059 (0.2666)  time: 5.1284  data: 0.0195  max mem: 74195
Epoch: [0]  [650/757]  eta: 0:09:12  lr: 4.9031481431799495e-05  loss: 0.1949 (0.2655)  time: 5.2841  data: 0.0201  max mem: 74195
Epoch: [0]  [660/757]  eta: 0:08:20  lr: 4.901658755145853e-05  loss: 0.2079 (0.2650)  time: 5.2450  data: 0.0196  max mem: 74195
Epoch: [0]  [670/757]  eta: 0:07:29  lr: 4.900169316826021e-05  loss: 0.2100 (0.2642)  time: 5.2818  data: 0.0196  max mem: 74195
Epoch: [0]  [680/757]  eta: 0:06:37  lr: 4.898679828201771e-05  loss: 0.2019 (0.2631)  time: 5.3074  data: 0.0212  max mem: 74195
Epoch: [0]  [690/757]  eta: 0:05:46  lr: 4.8971902892544085e-05  loss: 0.1996 (0.2623)  time: 5.2872  data: 0.0221  max mem: 74195
Epoch: [0]  [700/757]  eta: 0:04:54  lr: 4.895700699965225e-05  loss: 0.1987 (0.2613)  time: 5.0939  data: 0.0227  max mem: 74195
Epoch: [0]  [710/757]  eta: 0:04:02  lr: 4.894211060315498e-05  loss: 0.1986 (0.2605)  time: 5.1154  data: 0.0223  max mem: 74195
Epoch: [0]  [720/757]  eta: 0:03:11  lr: 4.8927213702864935e-05  loss: 0.1941 (0.2595)  time: 5.1643  data: 0.0216  max mem: 74195
Epoch: [0]  [730/757]  eta: 0:02:19  lr: 4.891231629859463e-05  loss: 0.1918 (0.2587)  time: 5.0812  data: 0.0230  max mem: 74195
Epoch: [0]  [740/757]  eta: 0:01:27  lr: 4.889741839015644e-05  loss: 0.1977 (0.2579)  time: 5.1776  data: 0.0239  max mem: 74195
Epoch: [0]  [750/757]  eta: 0:00:36  lr: 4.888251997736263e-05  loss: 0.1943 (0.2571)  time: 5.1207  data: 0.0222  max mem: 74195
Epoch: [0] Total time: 1:05:11
Test:  [   0/3811]  eta: 1:22:14    time: 1.2949  data: 0.7233  max mem: 74195
Test:  [ 100/3811]  eta: 0:05:11    time: 0.0725  data: 0.0014  max mem: 74195
Test:  [ 200/3811]  eta: 0:04:38    time: 0.0662  data: 0.0012  max mem: 74195
Test:  [ 300/3811]  eta: 0:04:22    time: 0.0711  data: 0.0014  max mem: 74195
Test:  [ 400/3811]  eta: 0:04:09    time: 0.0664  data: 0.0012  max mem: 74195
Test:  [ 500/3811]  eta: 0:03:56    time: 0.0643  data: 0.0011  max mem: 74195
Test:  [ 600/3811]  eta: 0:03:46    time: 0.0666  data: 0.0011  max mem: 74195
Test:  [ 700/3811]  eta: 0:03:37    time: 0.0658  data: 0.0011  max mem: 74195
Test:  [ 800/3811]  eta: 0:03:28    time: 0.0647  data: 0.0011  max mem: 74195
Test:  [ 900/3811]  eta: 0:03:20    time: 0.0651  data: 0.0011  max mem: 74195
Test:  [1000/3811]  eta: 0:03:12    time: 0.0658  data: 0.0011  max mem: 74195
Test:  [1100/3811]  eta: 0:03:04    time: 0.0646  data: 0.0011  max mem: 74195
Test:  [1200/3811]  eta: 0:02:57    time: 0.0642  data: 0.0011  max mem: 74195
Test:  [1300/3811]  eta: 0:02:49    time: 0.0644  data: 0.0011  max mem: 74195
Test:  [1400/3811]  eta: 0:02:42    time: 0.0641  data: 0.0010  max mem: 74195
Test:  [1500/3811]  eta: 0:02:35    time: 0.0642  data: 0.0010  max mem: 74195
Test:  [1600/3811]  eta: 0:02:28    time: 0.0650  data: 0.0010  max mem: 74195
Test:  [1700/3811]  eta: 0:02:21    time: 0.0650  data: 0.0011  max mem: 74195
Test:  [1800/3811]  eta: 0:02:14    time: 0.0652  data: 0.0011  max mem: 74195
Test:  [1900/3811]  eta: 0:02:07    time: 0.0641  data: 0.0011  max mem: 74195
Test:  [2000/3811]  eta: 0:02:00    time: 0.0640  data: 0.0011  max mem: 74195
Test:  [2100/3811]  eta: 0:01:53    time: 0.0646  data: 0.0010  max mem: 74195
Test:  [2200/3811]  eta: 0:01:46    time: 0.0647  data: 0.0011  max mem: 74195
Test:  [2300/3811]  eta: 0:01:40    time: 0.0641  data: 0.0011  max mem: 74195
Test:  [2400/3811]  eta: 0:01:33    time: 0.0640  data: 0.0011  max mem: 74195
Test:  [2500/3811]  eta: 0:01:26    time: 0.0642  data: 0.0011  max mem: 74195
Test:  [2600/3811]  eta: 0:01:19    time: 0.0640  data: 0.0011  max mem: 74195
Test:  [2700/3811]  eta: 0:01:13    time: 0.0645  data: 0.0010  max mem: 74195
Test:  [2800/3811]  eta: 0:01:06    time: 0.0638  data: 0.0010  max mem: 74195
Test:  [2900/3811]  eta: 0:00:59    time: 0.0655  data: 0.0011  max mem: 74195
Test:  [3000/3811]  eta: 0:00:53    time: 0.0643  data: 0.0010  max mem: 74195
Test:  [3100/3811]  eta: 0:00:46    time: 0.0643  data: 0.0010  max mem: 74195
Test:  [3200/3811]  eta: 0:00:40    time: 0.0639  data: 0.0011  max mem: 74195
Test:  [3300/3811]  eta: 0:00:33    time: 0.0644  data: 0.0010  max mem: 74195
Test:  [3400/3811]  eta: 0:00:26    time: 0.0645  data: 0.0011  max mem: 74195
Test:  [3500/3811]  eta: 0:00:20    time: 0.0650  data: 0.0011  max mem: 74195
Test:  [3600/3811]  eta: 0:00:13    time: 0.0648  data: 0.0011  max mem: 74195
Test:  [3700/3811]  eta: 0:00:07    time: 0.0642  data: 0.0010  max mem: 74195
Test:  [3800/3811]  eta: 0:00:00    time: 0.0640  data: 0.0011  max mem: 74195
Test: Total time: 0:04:09
Final results:
Mean IoU is 43.45

    precision@0.5 = 46.89
    precision@0.6 = 36.71
    precision@0.7 = 26.42
    precision@0.8 = 13.93
    precision@0.9 = 2.55
    overall IoU = 47.97

Average object IoU 43.451273011630335
Overall IoU 47.966758728027344
Better epoch: 0

/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
Traceback (most recent call last):
  File "train.py", line 320, in <module>
    main(args)
  File "train.py", line 304, in main
    'model_best_{}.pth'.format(args.model_id)))
  File "/mnt/petrelfs/huyutao/code/lavit/utils.py", line 202, in save_on_master
    torch.save(*args, **kwargs)
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/model_best_refcoco/1003_dynamic.pth'
/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
Traceback (most recent call last):
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/mnt/petrelfs/huyutao/anaconda3/envs/try/bin/python', '-u', 'train.py', '--local_rank=1', '--model', 'lavt', '--dataset', 'refcoco', '--model_id', 'refcoco/1003_dynamic', '--batch-size', '28', '--lr', '0.00005', '--wd', '1e-2', '--swin_type', 'base', '--pretrained_swin_weights', './pretrained_weights/swin_base_patch4_window12_384_22k.pth', '--epochs', '40', '--img_size', '480']' returned non-zero exit status 1.
srun: error: SH-IDC1-10-140-24-39: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=62555.0
mkdir: 无法创建目录"./models/coco_1003_dynamic": 文件已存在
srun: job 66320 queued and waiting for resources
srun: job 66320 has been allocated resources
srun: Job 66320 scheduled successfully!
Current QUOTA_TYPE is [spot], which means the job has occupied quota in SPOT_TOTAL under your partition.
[NOTE]: This job MAY BE PREEMPTED by other jobs of reserved QUOTA_TYPE.
[NOTE]: phx_priority has NO effect on job of spot quota type.

srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device
srun: error: Not using a pseudo-terminal, disregarding --pty option
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
RANK and WORLD_SIZE in environment: 0/4
RANK and WORLD_SIZE in environment: 1/4
RANK and WORLD_SIZE in environment: 3/4
RANK and WORLD_SIZE in environment: 2/4
Image size: 480
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.06s)
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.16s)
local rank 0 / global rank 0 successfully built train dataset.
lavt
Window size 12!
Initializing Multi-modal Swin Transformer weights from ./pretrained_weights/swin_base_patch4_window12_384_22k.pth
Epoch: [0]  [  0/378]  eta: 0:44:44  lr: 4.999702379968167e-05  loss: 0.7130 (0.7130)  time: 7.1007  data: 1.1840  max mem: 71768
Epoch: [0]  [ 10/378]  eta: 0:33:46  lr: 4.996726071357425e-05  loss: 0.6680 (0.6671)  time: 5.5081  data: 0.1200  max mem: 74191
Epoch: [0]  [ 20/378]  eta: 0:32:01  lr: 4.993749565751029e-05  loss: 0.6023 (0.6143)  time: 5.2806  data: 0.0135  max mem: 74191
Epoch: [0]  [ 30/378]  eta: 0:30:39  lr: 4.990772863005457e-05  loss: 0.4654 (0.5453)  time: 5.1629  data: 0.0139  max mem: 74191
Epoch: [0]  [ 40/378]  eta: 0:29:56  lr: 4.98779596297699e-05  loss: 0.3530 (0.4954)  time: 5.2620  data: 0.0142  max mem: 74191
Epoch: [0]  [ 50/378]  eta: 0:28:59  lr: 4.984818865521706e-05  loss: 0.3296 (0.4630)  time: 5.3304  data: 0.0144  max mem: 74191
Epoch: [0]  [ 60/378]  eta: 0:27:56  lr: 4.981841570495484e-05  loss: 0.3086 (0.4358)  time: 5.1807  data: 0.0147  max mem: 74191
Epoch: [0]  [ 70/378]  eta: 0:27:07  lr: 4.978864077754001e-05  loss: 0.3016 (0.4182)  time: 5.2335  data: 0.0152  max mem: 74191
Epoch: [0]  [ 80/378]  eta: 0:26:02  lr: 4.9758863871527325e-05  loss: 0.2985 (0.4029)  time: 5.1624  data: 0.0155  max mem: 74191
Epoch: [0]  [ 90/378]  eta: 0:25:11  lr: 4.972908498546954e-05  loss: 0.2891 (0.3921)  time: 5.1298  data: 0.0158  max mem: 74191
Epoch: [0]  [100/378]  eta: 0:24:32  lr: 4.969930411791738e-05  loss: 0.3035 (0.3829)  time: 5.5038  data: 0.0156  max mem: 74191
Epoch: [0]  [110/378]  eta: 0:23:39  lr: 4.966952126741952e-05  loss: 0.3014 (0.3756)  time: 5.5039  data: 0.0158  max mem: 74191
Epoch: [0]  [120/378]  eta: 0:22:46  lr: 4.963973643252264e-05  loss: 0.2930 (0.3683)  time: 5.2890  data: 0.0175  max mem: 74191
Epoch: [0]  [130/378]  eta: 0:21:51  lr: 4.960994961177135e-05  loss: 0.2925 (0.3624)  time: 5.2389  data: 0.0190  max mem: 74191
Epoch: [0]  [140/378]  eta: 0:21:00  lr: 4.9580160803708256e-05  loss: 0.2956 (0.3577)  time: 5.3085  data: 0.0189  max mem: 74191
Epoch: [0]  [150/378]  eta: 0:20:05  lr: 4.95503700068739e-05  loss: 0.2773 (0.3522)  time: 5.2875  data: 0.0186  max mem: 74191
Epoch: [0]  [160/378]  eta: 0:19:12  lr: 4.9520577219806776e-05  loss: 0.2773 (0.3482)  time: 5.2259  data: 0.0185  max mem: 74191
Epoch: [0]  [170/378]  eta: 0:18:19  lr: 4.9490782441043335e-05  loss: 0.2824 (0.3445)  time: 5.2932  data: 0.0182  max mem: 74191
Epoch: [0]  [180/378]  eta: 0:17:25  lr: 4.946098566911797e-05  loss: 0.2901 (0.3422)  time: 5.1999  data: 0.0185  max mem: 74191
Epoch: [0]  [190/378]  eta: 0:16:30  lr: 4.9431186902563e-05  loss: 0.2839 (0.3389)  time: 5.1150  data: 0.0191  max mem: 74191
Epoch: [0]  [200/378]  eta: 0:15:38  lr: 4.94013861399087e-05  loss: 0.2740 (0.3352)  time: 5.1972  data: 0.0191  max mem: 74191
Epoch: [0]  [210/378]  eta: 0:14:45  lr: 4.9371583379683264e-05  loss: 0.2669 (0.3322)  time: 5.2830  data: 0.0190  max mem: 74191
Epoch: [0]  [220/378]  eta: 0:13:53  lr: 4.9341778620412815e-05  loss: 0.2530 (0.3284)  time: 5.3146  data: 0.0193  max mem: 74191
Epoch: [0]  [230/378]  eta: 0:13:00  lr: 4.93119718606214e-05  loss: 0.2393 (0.3251)  time: 5.2810  data: 0.0196  max mem: 74191
Epoch: [0]  [240/378]  eta: 0:12:07  lr: 4.9282163098830984e-05  loss: 0.2393 (0.3216)  time: 5.2595  data: 0.0186  max mem: 74191
Epoch: [0]  [250/378]  eta: 0:11:14  lr: 4.9252352333561444e-05  loss: 0.2354 (0.3182)  time: 5.2259  data: 0.0185  max mem: 74191
Epoch: [0]  [260/378]  eta: 0:10:22  lr: 4.922253956333057e-05  loss: 0.2358 (0.3156)  time: 5.2686  data: 0.0194  max mem: 74191
Epoch: [0]  [270/378]  eta: 0:09:28  lr: 4.919272478665406e-05  loss: 0.2261 (0.3128)  time: 5.2675  data: 0.0191  max mem: 74191
Epoch: [0]  [280/378]  eta: 0:08:36  lr: 4.9162908002045495e-05  loss: 0.2230 (0.3094)  time: 5.1845  data: 0.0195  max mem: 74191
Epoch: [0]  [290/378]  eta: 0:07:43  lr: 4.9133089208016366e-05  loss: 0.2170 (0.3063)  time: 5.2644  data: 0.0186  max mem: 74191
Epoch: [0]  [300/378]  eta: 0:06:51  lr: 4.910326840307607e-05  loss: 0.2343 (0.3045)  time: 5.3457  data: 0.0182  max mem: 74191
Epoch: [0]  [310/378]  eta: 0:05:58  lr: 4.9073445585731855e-05  loss: 0.2444 (0.3023)  time: 5.3550  data: 0.0189  max mem: 74191
Epoch: [0]  [320/378]  eta: 0:05:05  lr: 4.9043620754488886e-05  loss: 0.2262 (0.3000)  time: 5.2765  data: 0.0187  max mem: 74191
Epoch: [0]  [330/378]  eta: 0:04:13  lr: 4.90137939078502e-05  loss: 0.2352 (0.2982)  time: 5.2525  data: 0.0184  max mem: 74191
Epoch: [0]  [340/378]  eta: 0:03:20  lr: 4.89839650443167e-05  loss: 0.2386 (0.2960)  time: 5.3482  data: 0.0176  max mem: 74191
Epoch: [0]  [350/378]  eta: 0:02:27  lr: 4.8954134162387145e-05  loss: 0.2153 (0.2938)  time: 5.3797  data: 0.0169  max mem: 74191
Epoch: [0]  [360/378]  eta: 0:01:35  lr: 4.8924301260558195e-05  loss: 0.2084 (0.2915)  time: 5.4195  data: 0.0173  max mem: 74191
Epoch: [0]  [370/378]  eta: 0:00:42  lr: 4.8894466337324344e-05  loss: 0.2084 (0.2894)  time: 5.3607  data: 0.0186  max mem: 74191
Epoch: [0] Total time: 0:33:16
Test:  [   0/3811]  eta: 0:55:31    time: 0.8742  data: 0.7304  max mem: 74191
Test:  [ 100/3811]  eta: 0:04:36    time: 0.0662  data: 0.0012  max mem: 74191
Test:  [ 200/3811]  eta: 0:04:13    time: 0.0653  data: 0.0011  max mem: 74191
Test:  [ 300/3811]  eta: 0:04:00    time: 0.0660  data: 0.0012  max mem: 74191
Test:  [ 400/3811]  eta: 0:03:51    time: 0.0651  data: 0.0011  max mem: 74191
Test:  [ 500/3811]  eta: 0:03:42    time: 0.0655  data: 0.0011  max mem: 74191
Test:  [ 600/3811]  eta: 0:03:35    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [ 700/3811]  eta: 0:03:27    time: 0.0652  data: 0.0012  max mem: 74191
Test:  [ 800/3811]  eta: 0:03:20    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [ 900/3811]  eta: 0:03:13    time: 0.0655  data: 0.0012  max mem: 74191
Test:  [1000/3811]  eta: 0:03:06    time: 0.0651  data: 0.0012  max mem: 74191
Test:  [1100/3811]  eta: 0:02:59    time: 0.0652  data: 0.0012  max mem: 74191
Test:  [1200/3811]  eta: 0:02:52    time: 0.0653  data: 0.0012  max mem: 74191
Test:  [1300/3811]  eta: 0:02:45    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [1400/3811]  eta: 0:02:39    time: 0.0652  data: 0.0012  max mem: 74191
Test:  [1500/3811]  eta: 0:02:32    time: 0.0659  data: 0.0012  max mem: 74191
Test:  [1600/3811]  eta: 0:02:25    time: 0.0651  data: 0.0011  max mem: 74191
Test:  [1700/3811]  eta: 0:02:19    time: 0.0655  data: 0.0012  max mem: 74191
Test:  [1800/3811]  eta: 0:02:12    time: 0.0650  data: 0.0012  max mem: 74191
Test:  [1900/3811]  eta: 0:02:05    time: 0.0653  data: 0.0013  max mem: 74191
Test:  [2000/3811]  eta: 0:01:59    time: 0.0651  data: 0.0012  max mem: 74191
Test:  [2100/3811]  eta: 0:01:52    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [2200/3811]  eta: 0:01:45    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [2300/3811]  eta: 0:01:39    time: 0.0653  data: 0.0012  max mem: 74191
Test:  [2400/3811]  eta: 0:01:32    time: 0.0649  data: 0.0012  max mem: 74191
Test:  [2500/3811]  eta: 0:01:26    time: 0.0651  data: 0.0012  max mem: 74191
Test:  [2600/3811]  eta: 0:01:19    time: 0.0650  data: 0.0012  max mem: 74191
Test:  [2700/3811]  eta: 0:01:12    time: 0.0652  data: 0.0012  max mem: 74191
Test:  [2800/3811]  eta: 0:01:06    time: 0.0649  data: 0.0012  max mem: 74191
Test:  [2900/3811]  eta: 0:00:59    time: 0.0658  data: 0.0012  max mem: 74191
Test:  [3000/3811]  eta: 0:00:53    time: 0.0654  data: 0.0012  max mem: 74191
Test:  [3100/3811]  eta: 0:00:46    time: 0.0652  data: 0.0012  max mem: 74191
Test:  [3200/3811]  eta: 0:00:40    time: 0.0650  data: 0.0012  max mem: 74191
Test:  [3300/3811]  eta: 0:00:33    time: 0.0650  data: 0.0011  max mem: 74191
Test:  [3400/3811]  eta: 0:00:26    time: 0.0650  data: 0.0012  max mem: 74191
Test:  [3500/3811]  eta: 0:00:20    time: 0.0654  data: 0.0011  max mem: 74191
Test:  [3600/3811]  eta: 0:00:13    time: 0.0651  data: 0.0011  max mem: 74191
Test:  [3700/3811]  eta: 0:00:07    time: 0.0650  data: 0.0011  max mem: 74191
Test:  [3800/3811]  eta: 0:00:00    time: 0.0651  data: 0.0011  max mem: 74191
/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
Test: Total time: 0:04:09
Final results:
Mean IoU is 36.89

    precision@0.5 = 39.07
    precision@0.6 = 30.81
    precision@0.7 = 22.02
    precision@0.8 = 12.44
    precision@0.9 = 2.15
    overall IoU = 43.06

Average object IoU 36.887135972971926
Overall IoU 43.0632209777832
Better epoch: 0

/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
/mnt/petrelfs/huyutao/anaconda3/envs/try/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
Epoch: [1]  [  0/378]  eta: 0:42:20  lr: 4.8870596942312677e-05  loss: 0.1799 (0.1799)  time: 6.7222  data: 1.1628  max mem: 74191
Epoch: [1]  [ 10/378]  eta: 0:33:01  lr: 4.8840758376749305e-05  loss: 0.2074 (0.2012)  time: 5.3847  data: 0.1200  max mem: 74191
Epoch: [1]  [ 20/378]  eta: 0:31:41  lr: 4.881091778555422e-05  loss: 0.2024 (0.2005)  time: 5.2405  data: 0.0152  max mem: 74191
Epoch: [1]  [ 30/378]  eta: 0:30:35  lr: 4.8781075167213754e-05  loss: 0.1942 (0.1995)  time: 5.2131  data: 0.0158  max mem: 74191
Epoch: [1]  [ 40/378]  eta: 0:30:06  lr: 4.875123052021208e-05  loss: 0.1947 (0.1997)  time: 5.3775  data: 0.0170  max mem: 74191
Epoch: [1]  [ 50/378]  eta: 0:29:10  lr: 4.8721383843031195e-05  loss: 0.1912 (0.1974)  time: 5.4350  data: 0.0167  max mem: 74191
srun: forcing job termination
srun: Job step aborted: Waiting up to 2 seconds for job step to finish.
srun: Easily find out why your job was killed by following the link below:
	https://docs.phoenix.sensetime.com/FAQ/SlurmFAQ/Find-out-why-my-job-was-killed/
slurmstepd: error: *** STEP 66320.0 ON SH-IDC1-10-140-24-96 CANCELLED AT 2022-10-05T13:53:51 ***
srun: error: Timed out waiting for job step to complete
